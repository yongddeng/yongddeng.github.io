<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
	<link rel="stylesheet" href="/assets/css/atom-one-light.css">
    
        <title>206. mode of convergence</title>
		<link rel="stylesheet" type="text/css" href="/assets/css/002.css">
    
	<link rel="stylesheet" href="/assets/css/font-awesome.min.css">
	<link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon">
	<link rel="icon" href="/assets/img/favicon.ico" type="image/x-icon">
	<script src="/assets/js/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
	
		<!--http://benlansdell.github.io/computing/mathjax/-->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: [
      "tex2jax.js",
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    jax: ["input/TeX", "output/CommonHTML"],
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<!-- You may add the following into MathJax.Hub.Config:
CommonHTML: {
    scale: 85
}-->
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	
</head>
<body>
	<div class="wrapper">
		<div class="default_title">
			<img src="/assets/img/mycomputer.png" />
			
				<h1>Hikikomori</h1>
			
		</div>
		<ul class="topbar">
	<a href="/me"><li><u>A</u>bout</li></a>
	<a href="https://www.linkedin.com/in/sung-kim-28b78a7b/" target="_blank"><li><u>L</u>inkedIn</li></a>
	<!-- 
		<a href="http://soundcloud.com/h01000110" target="_blank"><li><u>S</u>oundcloud</li></a>
	-->
</ul>
		<div class="tag_list">
			<ul id="tag-list">
				<li><a href="/" ><img src="/assets/img/disk.png" />(C:)</a>
			<ul>
				
				
				<li><a href="/tag/cs300/" title="cs300"><img src="/assets/img/folder.ico" />cs300</a></li>
				
				<li><a href="/tag/cs400/" title="cs400"><img src="/assets/img/folder.ico" />cs400</a></li>
				
				<li><a href="/tag/math200/" title="math200"><img src="/assets/img/folder.ico" />math200</a></li>
				
				<li><a href="/tag/math500/" title="math500"><img src="/assets/img/folder.ico" />math500</a></li>
				
			</ul>
				</li>
			</ul>
		</div>
		<div class="post_list">
			
				<ul>
					
					<li><a href="/20240201/functional-analysis" title="501. functional analysis"><img src="/assets/img/file.ico" title="501. functional analysis" />501. functional analysis</a></li>
					
					<li><a href="/20240105/parallel-computing" title="Parallel Computing"><img src="/assets/img/file.ico" title="Parallel Computing" />Parallel Computing</a></li>
					
					<li><a href="/20240104/networking" title="Networking"><img src="/assets/img/file.ico" title="Networking" />Networking</a></li>
					
					<li><a href="/20240103/virtualisation" title="Virtualisation"><img src="/assets/img/file.ico" title="Virtualisation" />Virtualisation</a></li>
					
					<li><a href="/20240102/tmp" title="402. operating system"><img src="/assets/img/file.ico" title="402. operating system" />402. operating system</a></li>
					
					<li><a href="/20240102/operating-system" title="402. operating system"><img src="/assets/img/file.ico" title="402. operating system" />402. operating system</a></li>
					
					<li><a href="/20240101/computer" title="401. dl compilation"><img src="/assets/img/file.ico" title="401. dl compilation" />401. dl compilation</a></li>
					
					<li><a href="/20230101/ml-paper" title="301. ml literature"><img src="/assets/img/file.ico" title="301. ml literature" />301. ml literature</a></li>
					
					<li><a href="/20220112/markov-chain" title="212. markov chain"><img src="/assets/img/file.ico" title="212. markov chain" />212. markov chain</a></li>
					
					<li><a href="/20220111/martingale" title="211. martingale"><img src="/assets/img/file.ico" title="211. martingale" />211. martingale</a></li>
					
					<li><a href="/20220110/stochastic-process" title="210. stochastic process"><img src="/assets/img/file.ico" title="210. stochastic process" />210. stochastic process</a></li>
					
					<li><a href="/20220109/laws-of-the-iterated-logarithm" title="209. law of the iterated logarithm"><img src="/assets/img/file.ico" title="209. law of the iterated logarithm" />209. law of the iterated logarithm</a></li>
					
					<li><a href="/20220108/central-limit-theorem" title="208. central limit theorem"><img src="/assets/img/file.ico" title="208. central limit theorem" />208. central limit theorem</a></li>
					
					<li><a href="/20220107/laws-of-large-number" title="207. law of large number"><img src="/assets/img/file.ico" title="207. law of large number" />207. law of large number</a></li>
					
					<li><a href="/20220106/modes-of-convergence" title="206. mode of convergence"><img src="/assets/img/file.ico" title="206. mode of convergence" />206. mode of convergence</a></li>
					
					<li><a href="/20220105/characteristic-function" title="205. characteristic function"><img src="/assets/img/file.ico" title="205. characteristic function" />205. characteristic function</a></li>
					
					<li><a href="/20220104/inequality" title="204. inequality"><img src="/assets/img/file.ico" title="204. inequality" />204. inequality</a></li>
					
					<li><a href="/20220103/expectation" title="203. expectated value"><img src="/assets/img/file.ico" title="203. expectated value" />203. expectated value</a></li>
					
					<li><a href="/20220102/random-variable" title="202. random variable"><img src="/assets/img/file.ico" title="202. random variable" />202. random variable</a></li>
					
					<li><a href="/20220101/probability" title="201. probability theory"><img src="/assets/img/file.ico" title="201. probability theory" />201. probability theory</a></li>
					
				</ul>
			
		</div>
		<div class="post_total">
			
				<div class="left">20 object(s)</div>
			
			<div class="right">&nbsp;</div>
		</div>
	</div>
	
        <div class="content">
			<div class="post_title">
				<img src="/assets/img/file.png" />
				<h1>206. mode of convergence</h1>
				<a href="/"><div class="btn"><span class="fa fa-times"></span></div></a>
				<div class="btn btn_max"><span class="fa fa-window-maximize"></span></div>
				<div class="btn"><span class="fa fa-window-minimize"></span></div>
			</div>
			<ul class="topbar">
				<li>January 6, 2022</li>
			</ul>
			<div class="post_content">
        		<h1 id="mode-of-convergence">Mode of Convergence</h1>
<hr />
<p>One of the basis of probability theory is the stabilisation of the <a href="https://www.mathsisfun.com/data/relative-frequency.html">relative frequencies</a>. That is, we want to systematically predict an event which may or may not be unchanging as it goes far enough into the sequence.</p>

<h2 id="i">I</h2>
<hr />

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Mode</strong></th>
      <th style="text-align: left"><strong>Alias</strong></th>
      <th style="text-align: left"><strong>Definition</strong></th>
      <th style="text-align: center"><strong>Notation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="">completely</a></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$\Sigma_{n=1}^{\infty} P(\lvert X_n - X \rvert &gt; \varepsilon) &lt; \infty$, for all $\varepsilon &gt; 0$</td>
      <td style="text-align: center">$X_n \xrightarrow{c.c.} X$</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="">almost surely</a></td>
      <td style="text-align: left">strong convergence (with reference to the strong LLN)</td>
      <td style="text-align: left">$P(\lim_{n \to \infty} X_n - X = 0) = 1$</td>
      <td style="text-align: center">$X_n \xrightarrow{a.s.} X$</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="">in Probability</a></td>
      <td style="text-align: left">weak convergence (with reference to the weak LLN)</td>
      <td style="text-align: left">$\lim_{n \to \infty} P(\lvert X_n - X \rvert \leq \varepsilon) = 1$, for all $\varepsilon &gt; 0$</td>
      <td style="text-align: center">$X_n \xrightarrow{p} X$</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="">in $r$-Mean</a></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$\lim_{n \to \infty} \operatorname{E}{\vert X_n - X \rvert}^r = 0$, where $r \geq 1$</td>
      <td style="text-align: center">$X_n \xrightarrow{r} X$</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="">in Distribution</a></td>
      <td style="text-align: left">weakest convergence (with reference to the CLT)</td>
      <td style="text-align: left">$\lim_{n \to \infty} F_{X_n} = F_X$, for all $x \in C(F_X)$</td>
      <td style="text-align: center">$X_n \xrightarrow{d} X$</td>
    </tr>
  </tbody>
</table>

<p>$\\$</p>

<p>A few notes on the modes of convergence: (i) The “complete convergence” can be useful if we work with respect to the Borel-Cantelli lemma; (ii) The terms “almost sure convergence” and “<a href="">convergence with probability $1$</a>” are used interchangably; (iii) We may rewrite the “convergence in probability” by $\lim_{n\to\infty}P(\vert X_n-X \vert &gt;\varepsilon)=0$; (iv) The “convergence in $r$-mean” means “<a href="">convergence in $L^p$-space</a>” for every $p = r \geq 1$ and a higher order convergence implies lower order ones; (v) Each element $X_n$ of a sequence need not be defined on the same probability space for the “convergence in distribution” as they are studied only in terms of $F_{X_n}$;</p>

<p>The source of knowledge consented some abuse of notations. In particular, given a limiting random variable $X := X_{\infty} \sim \mathcal{N}(0,1)$, we are allowed to denote $X_n \xrightarrow{d} X$ rather than explicitly writing $X_n \xrightarrow{d} X$ as $n\to\infty$. We should emphasise that only the continuity points of $F_X$ are taken for the convergence in distribution. For example, if $(X_n)_{n\in\mathbb{N}}$ consists of $X_n = n^{-1}$ and $X_n \xrightarrow{p} X := 0$ (i.e. $X$ is <a href="">degenerate</a>), then $X_n \not\xrightarrow{d} X$ for every $x \notin C(F_X)$. That is, if $(F_{X_n})_{n\in\mathbb{N}}$ is a sequence of distribution functions such that $F_{X_n}(x)=0$ for $x &lt; n^{-1}$ and $F_{X_n}(x)=1$ for $x \geq n^{-1}$, then $F_{X_n} \to F_X$ as $n\to\infty$ only when $x\neq0$ in which $P(X=0) = 1$.</p>

<p>If $(X_n)_{n\in\mathbb{N}}$ converges completely, almost surely, in probability, in $r$-mean, or in distribution to $X$, then a random variable $X$ is unique. In particular, for the preceding four modes, if $X_{n} \to X$ and $X_{n} \to Y$, then $X = Y$ almost surely. Whereas, if $X_n$ converge in dist. to $X$ and $Y$, then $F_{X}(x)=F_{Y}(x)$ for all $x \in C(F_{X})$. On the other hand, for all $x \in C(F_{X}) \cap C(F_{Y})$, the triangle inequality shows that $\vert F_{X} - F_{Y} \vert \leq \vert F_{X} - F_{X_n} \vert + \vert F_{X_n}-F_{Y} \vert \to 0$ as $n\to\infty$. If $(X_{n})_{n\in\mathbb{N}}$ and $(Y_{n})_{n\in\mathbb{N}}$ converge almost surely, in probability, or in $r$-mean to $X$ and $Y$, respectively, then $aX_{n} + bY_{n} \to aX + bY$ for all $a,b\in\mathbb{R}$ correspondingly to each mode <strong>(#1)</strong>.</p>

<h2 id="ii">II</h2>
<hr />
<p>$(1) \begin{array}{ccccc} X_n \xrightarrow{c.c.} X &amp; \Longrightarrow &amp; X_n \xrightarrow{a.s.} X &amp; \Longrightarrow &amp; X_n \xrightarrow{p} X &amp; \Longrightarrow &amp; X_n \xrightarrow{d} X \end{array}$</p>

<p>$(2) \begin{array}{ccccc} X_n \xrightarrow{r} X &amp; \Longrightarrow &amp; X_n \xrightarrow{p} X \end{array}$</p>

<p>The first relation in $(1)$ comes by the 1st Borel-Canteli lemma. If $X_n$ are ind. and $X$ is degenerate, then its converse is true due to the 2nd Borel-Canteli lemma. The relation $(2)$ comes by Markov’s inequality $P(\vert Y_n \vert &gt; \varepsilon) \leq \varepsilon^{-r}\operatorname{E}{\vert Y_n \vert}^r$, where $Y_n = X_n-X$. The converse $X_n \xrightarrow{p} X \Longrightarrow X_n \xrightarrow{r} X$ holds if a weakly convergent sequence $({\vert X_n \vert}^p)_{n\in\mathbb{N}}$ is <a href="">uniformly integrable</a> (u.i.). Formally put, $(X_n)_{n\in\mathbb{N}}$ is u.i. if for all $\varepsilon &gt; 0$ there exists $B_\varepsilon \in [0, \infty)$ such that $\sup_{n} \operatorname{E}({\vert X_n \vert}I_{\vert X_n \vert &gt; B_\varepsilon}) \leq \varepsilon$ uniformly in $n\in\mathbb{N}$. We simply denote $\lim_{b\to\infty} \sup_n \operatorname{E}({\vert X_n \vert}I_{\vert X_n \vert &gt; b})=0$ <strong>(#2)</strong>. While $X$ is u.i. if and only if $\operatorname{E}\vert X \vert &lt; \infty$, the details of the u.i. of $X$ and $(X_{n})_{n\in\mathbb{N}}$ follow.</p>

<p>If we put $\operatorname{E}\vert X \vert = \operatorname{E}({\vert X \vert}I_{\vert X \vert \leq b}) + \operatorname{E}({\vert X \vert}I_{\vert X \vert &gt; b})$, then ${\vert X \vert}I_{\vert X \vert \leq b} \geq 0$ and also ${\vert X \vert}I_{\vert X \vert \leq b} \nearrow \vert X \vert$ as $b\to\infty$. If we apply MCT for $\lim_{a\to\infty}\operatorname{E}({\vert X \vert}I_{\vert X \vert \leq b}) = \operatorname{E}(\lim_{a\to\infty}{\vert X \vert}I_{\vert X \vert \leq b}) = \operatorname{E}{\vert X \vert}$, then $\lim_{a\to\infty}\operatorname{E}({\vert X \vert}I_{\vert X \vert &gt; b}) = 0$ for all $\operatorname{E}{\vert X \vert} &lt; \infty$. Thus, $(X_n)_{n\in\mathbb{N}}$ is u.i. if and only if it holds (i) boundness: $\sup_n\operatorname{E}{\vert X_n \vert}&lt;\infty$ <strong>(#3)</strong>; (ii) <a href="">uniform continuity</a>: for all $\varepsilon &gt; 0$ there exists $\delta &gt; 0$. That is, for all $A\in\mathcal{F}$ with $P(A) \leq \delta$ one has $\sup_n \operatorname{E}({\vert X_n \vert} I_A) = \sup_n\int_{A}{\vert X_n \vert}\,\mathrm{d}P \leq \varepsilon$. We put $\sup_n\operatorname{E}{\vert X_n I_A \vert} \to 0$ as $P(A) \to 0$; Since $\operatorname{E}({\vert X_n \vert}I_A) \leq aP(A) + \operatorname{E}({\vert X_n \vert} I_{\vert X_n \vert &gt;a}) \leq a\delta + \varepsilon/2 &lt; \epsilon$, Markov’s inequality on $A_n = \lbrace \vert X_n \vert &gt; a \rbrace$ can show the necessity.</p>

<p>The converse relation under the u.i. is a generalisation of the <a href="">Vitali convergence theorem</a> (which generalises the DCT). Measure theoretically, the theorem says that $(f_n)_{n\in\mathbb{N}} \subset L^p$ on a finite measure space $(X, \Sigma, \mu)$ converges in $L^p$ to $f \in L^p$ if and only if (i) $f_n$ converges in $\mu$-measure to $f$ <strong>(#4)</strong>; (ii) $({\vert f_n \vert}^p)_{n\in\mathbb{N}}$ is u.i.; $P(\Omega)=1$ is indeed finite by axioms. The finiteness condition can be relaxed if, in addition, (iii) for all $\varepsilon&gt;0$ there exists $E_{\varepsilon} \in \Sigma$ such that $(F\in\Sigma) \land (F\cap{E_\varepsilon}) = \emptyset$ and $\sup_n\int_{F}{\vert f_n \vert}^p\,\mathrm{d}\mu &lt; \varepsilon^p$. If we suppose $E_\epsilon = X$ whenever $\mu(X)&lt;\infty$, then $F=\emptyset$ is the only element contained in $\Sigma$ such that $E_\varepsilon \cap F =\emptyset$ and $\int_\emptyset {\vert f_n \vert}^p = 0$ <strong>(#5)</strong>.</p>

<h2 id="iii">III</h2>
<hr />
<p>// Skorokhod’s representation theorem</p>

<h2>**</h2>
<hr />
<p><strong>(#1)</strong> X_n Y_n \to XY$ correspondingly to each mode of convergence. <strong>(#2)</strong> Measure theoretically, u.i. holds for an uncountable set of functions indexed by $I$, and a sequence is merely a countable set with $I=\mathbb{N}$. <strong>(#3)</strong> $X = (X_i)_{i \in I}$ is bounded in norm as a subset of the vector space $L^1$. A finite collection of integrable r.v.s are u.i.. <strong>(#4)</strong> Given $(X,\Sigma,\mu)$, we say $f_n$ converges “globally” in measure to $f$ if $\lim_{n\to\infty} \mu(\lbrace x \in X: {\vert f(x)-f_n(x) \vert} \geq \varepsilon \rbrace) = 0$, and “locally” if $\lim_{n\to\infty} \mu(\lbrace x \in F: {\vert f(x)-f_n(x) \vert} \geq \varepsilon \rbrace) = 0$, where $F \in \Sigma$ and $\mu(F) &lt; \infty$; <strong>(#5)</strong> If $\mu(X) &lt; \infty$, then the existence of a dominating integrable function $g$ can be replaced by the u.i. of the sequence $(f_{n})_{n\in\mathbb{N}}$.</p>

				
					<br>
<hr>
<br>
<div class="comment">
	<p>I gathered words solely for my own purposes without any intention to break the rigorosity of the subjects.<br>
	Well, I prefer eating corn in spiral <i class="fa fa-cutlery"></i>.</p>
</div>
				
			</div>
		</div>
    
	<script src="/assets/js/001.js"></script>
	<script src="/assets/js/002.js"></script>
	<div class="footer">
		<p>Code licensed under <a href="https://github.com/h01000110/h01000110.github.io/blob/master/LICENSE" target="_blank">MIT License</a></p>
	</div>
</body>
</html>